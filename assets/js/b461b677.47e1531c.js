"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[338],{3905:(e,n,a)=>{a.d(n,{Zo:()=>c,kt:()=>k});var t=a(7294);function o(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function s(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function r(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?s(Object(a),!0).forEach((function(n){o(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function l(e,n){if(null==e)return{};var a,t,o=function(e,n){if(null==e)return{};var a,t,o={},s=Object.keys(e);for(t=0;t<s.length;t++)a=s[t],n.indexOf(a)>=0||(o[a]=e[a]);return o}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(t=0;t<s.length;t++)a=s[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var i=t.createContext({}),d=function(e){var n=t.useContext(i),a=n;return e&&(a="function"==typeof e?e(n):r(r({},n),e)),a},c=function(e){var n=d(e.components);return t.createElement(i.Provider,{value:n},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},m=t.forwardRef((function(e,n){var a=e.components,o=e.mdxType,s=e.originalType,i=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=d(a),m=o,k=p["".concat(i,".").concat(m)]||p[m]||u[m]||s;return a?t.createElement(k,r(r({ref:n},c),{},{components:a})):t.createElement(k,r({ref:n},c))}));function k(e,n){var a=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var s=a.length,r=new Array(s);r[0]=m;var l={};for(var i in n)hasOwnProperty.call(n,i)&&(l[i]=n[i]);l.originalType=e,l[p]="string"==typeof e?e:o,r[1]=l;for(var d=2;d<s;d++)r[d]=a[d];return t.createElement.apply(null,r)}return t.createElement.apply(null,a)}m.displayName="MDXCreateElement"},5009:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>i,contentTitle:()=>r,default:()=>u,frontMatter:()=>s,metadata:()=>l,toc:()=>d});var t=a(7462),o=(a(7294),a(3905));const s={title:"Cluster topology - Cassandra rack aware deployments",sidebar_label:"Cluster topology"},r=void 0,l={unversionedId:"configuration_deployment/cluster_topology",id:"configuration_deployment/cluster_topology",title:"Cluster topology - Cassandra rack aware deployments",description:"CassKop rack awareness feature helps to spread the Cassandra nodes replicas among different racks in the",source:"@site/docs/3_configuration_deployment/4_cluster_topology.md",sourceDirName:"3_configuration_deployment",slug:"/configuration_deployment/cluster_topology",permalink:"/casskop/docs/configuration_deployment/cluster_topology",draft:!1,editUrl:"https://github.com/cscetbon/casskop/edit/master/website/docs/3_configuration_deployment/4_cluster_topology.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Cluster topology - Cassandra rack aware deployments",sidebar_label:"Cluster topology"},sidebar:"docs",previous:{title:"Storage",permalink:"/casskop/docs/configuration_deployment/storage"},next:{title:"Cassandra Configuration",permalink:"/casskop/docs/configuration_deployment/cassandra_configuration"}},i={},d=[{value:"Quick overview",id:"quick-overview",level:2},{value:"Kubernetes nodes labels",id:"kubernetes-nodes-labels",level:2},{value:"Configuring pod scheduling",id:"configuring-pod-scheduling",level:2},{value:"Cassandra node placement in the Kubernetes cluster",id:"cassandra-node-placement-in-the-kubernetes-cluster",level:3},{value:"Node affinity",id:"node-affinity",level:4},{value:"Pod anti affinity",id:"pod-anti-affinity",level:4},{value:"Using dedicated nodes",id:"using-dedicated-nodes",level:4},{value:"Configuring hard antiAffinity in Cassandra cluster",id:"configuring-hard-antiaffinity-in-cassandra-cluster",level:3},{value:"Cassandra notion of dc and racks",id:"cassandra-notion-of-dc-and-racks",level:2},{value:"Configure the CassandraCluster CRD for dc &amp; rack",id:"configure-the-cassandracluster-crd-for-dc--rack",level:2},{value:"How CassKop configures dc and rack in Cassandra",id:"how-casskop-configures-dc-and-rack-in-cassandra",level:2}],c={toc:d},p="wrapper";function u(e){let{components:n,...s}=e;return(0,o.kt)(p,(0,t.Z)({},c,s,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"CassKop rack awareness feature helps to spread the Cassandra nodes replicas among different racks in the\nkubernetes infrastructure. Enabling rack awareness helps to improve availability of Cassandra nodes and the data they\nare hosting, through correct use of Cassandra's replication factor."),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"Rack might represent an availability zone, data center or an actual physical rack in your data center.")),(0,o.kt)("h2",{id:"quick-overview"},"Quick overview"),(0,o.kt)("p",null,"CassKop awareness can be configured in the ",(0,o.kt)("inlineCode",{parentName:"p"},"CassandraCluster.spec.topology")," section."),(0,o.kt)("p",null,"If the ",(0,o.kt)("inlineCode",{parentName:"p"},"topology")," section is missing then CassKop will create a default Cassandra DC ",(0,o.kt)("inlineCode",{parentName:"p"},"dc1")," and a default Rack\n",(0,o.kt)("inlineCode",{parentName:"p"},"rack1"),".\nIn this case, CassKop will not use specific kubernetes nodes labels for placement and in consequence the cluster is\nnot rack aware."),(0,o.kt)("p",null,"In the ",(0,o.kt)("inlineCode",{parentName:"p"},"topology")," section we can declare all the Cassandra Datacenters (DCs) and Racks, and for each of them we provide\nlabels which will need to match the labels assigned to the Kubernetes cluster nodes."),(0,o.kt)("p",null,"Each of our rack targets Kubernetes nodes having the combination of labels defined in the ",(0,o.kt)("inlineCode",{parentName:"p"},"dc")," section and in the ",(0,o.kt)("inlineCode",{parentName:"p"},"rack"),"\nsection. The labels are used in Kubernetes when scheduling the Cassandra pods to kubernetes nodes.\nThis has the effect of spreading the Cassandra nodes across physical zones."),(0,o.kt)("admonition",{type:"important"},(0,o.kt)("p",{parentName:"admonition"},"CassKop doesn't rely on specific labels and will adapt to any topology you may define in your\ndatacenter or cloud provider.")),(0,o.kt)("h2",{id:"kubernetes-nodes-labels"},"Kubernetes nodes labels"),(0,o.kt)("p",null,"Cassandra will run on Kubernetes nodes, which may already have some labels representing their geographic topology."),(0,o.kt)("p",null,"Example :"),(0,o.kt)("p",null,(0,o.kt)("img",{src:a(9693).Z,width:"1320",height:"1046"})),(0,o.kt)("p",null,"Example of labels for node001 in our dc:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"location.myorg.com/bay=1\nlocation.myorg.com/building=building\nlocation.myorg.com/label=SC_K08_-_KUBERNETES\nlocation.myorg.com/room=Salle_1\nlocation.myorg.com/site=SiteName\nlocation.myorg.com/street=Rue_3\n")),(0,o.kt)("p",null,"In the cloud the labels used for topology may better look like :"),(0,o.kt)("p",null,(0,o.kt)("img",{src:a(9693).Z,width:"1320",height:"1046"})),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"beta.kubernetes.io/fluentd-ds-ready=true\nfailure-domain.beta.kubernetes.io/region=europe-west1\nkubernetes.io/hostname=gke-demo-default-pool-0c404f82-0100\nbeta.kubernetes.io/arch=amd64\nfailure-domain.beta.kubernetes.io/zone=europe-west1-d\nbeta.kubernetes.io/os=linux\ncloud.google.com/gke-os-distribution=cos\nbeta.kubernetes.io/instance-type=n1-standard-4\ncloud.google.com/gke-nodepool=default-pool\n")),(0,o.kt)("p",null,"The idea is to use the Kubernetes nodes labels which refer to their physical position in the datacenters to allow or\nnot Cassandra Pods placement."),(0,o.kt)("p",null,"Because CassKop manages its Cassandra node pods through\n",(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/"},"statefulsets"),",\neach pod will inherit the placement configuration of its parent statefulset.\nIn order to place pods on different racks, we need to associate a new statefulset with specialized node\nplacement constraints for each Cassandra rack we define."),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"Because the AZ feature was not yet available for statefulsets when we began to develop CassKop, we chose to\nimplement 1 statefulset for 1 Cassandra Rack. Hopefully, we will be able to benefit of improvements about the\ntopology-aware dynamic provisioning feature proposed in future version of K8S (more information here :\n",(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/blog/2018/10/11/topology-aware-volume-provisioning-in-kubernetes/"},"https://kubernetes.io/blog/2018/10/11/topology-aware-volume-provisioning-in-kubernetes/"))),(0,o.kt)("p",null,"See an example of configuration with topology : ",(0,o.kt)("a",{parentName:"p",href:"https://raw.githubusercontent.com/cscetbon/casskop/master/config/samples/cassandracluster-demo.yaml"},"cassandracluster-demo-gke.yaml")),(0,o.kt)("h2",{id:"configuring-pod-scheduling"},"Configuring pod scheduling"),(0,o.kt)("p",null,"When two applications are scheduled to the same Kubernetes node, both applications might use the same resources like\ndisk I/O and impact performances. It may be recommended to schedule Cassandra nodes in a way that avoids sharing nodes\nwith other critical workloads. Using the right nodes or dedicated a set of nodes only for cassandra are the best ways to\navoid such problems."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/configuration/assign-pod-node/"},"Placement of Pods")," in a Statefulsets are done\nusing ",(0,o.kt)("strong",{parentName:"p"},"NodeAffinity")," and ",(0,o.kt)("strong",{parentName:"p"},"PodAntiAffinity")," :"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://kubernetes.io/docs/concepts/configuration/assign-pod-node/"},"nodeAffinity")," will be used to select specific\nnodes which have specific targeted labels."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity"},"podAntiAffinity")," can\nbe used to ensure that critical applications are never scheduled on the same node.")),(0,o.kt)("h3",{id:"cassandra-node-placement-in-the-kubernetes-cluster"},"Cassandra node placement in the Kubernetes cluster"),(0,o.kt)("h4",{id:"node-affinity"},"Node affinity"),(0,o.kt)("p",null,"To target a Specific Kubernetes group of Nodes CassKop needs to define a specific ",(0,o.kt)("strong",{parentName:"p"},"nodeAffinity"),"\nsection in the targeted ",(0,o.kt)("inlineCode",{parentName:"p"},"dc-rack")," statefulset to match specific kubernetes nodes labels."),(0,o.kt)("p",null,"Example. If we want to deploy our statefulset only on nodes which have these labels :"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"location.myorg.com/site=Valbonne\nlocation.myorg.com/building=HT2\nlocation.myorg.com/room=Salle_1\nlocation.myorg.com/street=Rue_11\n")),(0,o.kt)("p",null,"CassKop need to add this section in the Statefulset definition :"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n          - key: location.myorg.com/building\n            operator: In\n            values:\n            - HT2\n          - key: location.myorg.com/room\n            operator: In\n            values:\n            - Salle_1\n          - key: location.myorg.com/site\n            operator: In\n            values:\n            - Valbonne\n          - key: location.myorg.com/street\n            operator: In\n            values:\n            - Rue_9\n")),(0,o.kt)("p",null,"All Pods that will be created from this statefulset will target only nodes which have these 4 labels.\nIf there is no kubernetes nodes available with these labels, then the statefulset will remain stuck in a pending state,\nuntil we correct either labels on nodes, or deployment constraints definition of the statefulset."),(0,o.kt)("p",null,"We can also use specific labels to dedicate some kubernetes nodes to some type of work, for instance dedicated some\nnodes for Cassandra."),(0,o.kt)("p",null,"You can define custom labels on kubernetes nodes :"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl label node <your-node> <label-name>=<label-value>\n")),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"This is done automatically by combining the labels you specify in the Cassandra CRD definition in the ",(0,o.kt)("inlineCode",{parentName:"p"},"Topology"),"\nsection.")),(0,o.kt)("h4",{id:"pod-anti-affinity"},"Pod anti affinity"),(0,o.kt)("p",null,"If we lose a Kubernetes node, then we may want to limit the impact to loosing only one Cassandra node. Otherwise,\ndepending on the replication factor, we may have a data loss."),(0,o.kt)("p",null,"In our CassandraCluster, the statefulset will target a pool of Kubernetes nodes using it's NodeSelector we just saw\nabove.\nAll these Pods will inherit the specific labels from the Statefulset."),(0,o.kt)("p",null,'To implement the limitation "one Cassandra Pod per Kubernetes node", we use the pod definition section\n',(0,o.kt)("inlineCode",{parentName:"p"},"podAntiAffinity"),". This tells kubernetes that it can't deploy to a Kubernetes node, if a pod having the same labels\nalready exist."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n      - podAffinityTerm:\n          labelSelector:\n            matchLabels:\n              app: cassandracluster\n              cassandracluster: cassandra\n              cluster: k8s.kaas\n          topologyKey: kubernetes.io/hostname\n        weight: 100\n")),(0,o.kt)("p",null,"This Tells that we ",(0,o.kt)("strong",{parentName:"p"},"Require")," not deploy to a node if a pod already exists with these existing labels."),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"This is configured by default by CassKop")),(0,o.kt)("h4",{id:"using-dedicated-nodes"},"Using dedicated nodes"),(0,o.kt)("p",null,"Cluster administrators can mark selected kubernetes nodes as tainted. Nodes with taints are excluded from regular\nscheduling and normal pods will not be scheduled to run on them. Only services which can tolerate the taint set on the\nnode can be scheduled on it. The only other services running on such nodes will be kubernetes system services such  as\nlog collectors or software defined networks"),(0,o.kt)("p",null,"Taints can be used to create dedicated nodes. Running Cassandra on dedicated nodes can have many advantages. There will\nbe no other applications running on the same nodes which could cause disturbance or consume the resources needed  for\nCassandra. That can lead to improved performance and stability."),(0,o.kt)("p",null,"Example of tainting a node :"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl taint node <your-node> dedicated=Cassandra:NoSchedule\n")),(0,o.kt)("p",null,"Additionally, add a label to the selected nodes as well"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl label node <your-node> dedicated=Cassandra\n")),(0,o.kt)("p",null,"Pod tolerations like pod annotations can be added to created pods by using the pod entry in the spec section of the cassandracluster object as below :"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'kind: "CassandraCluster"\n...\nspec:\n  ...\n  pod:\n    tolerations:\n    - key: "dedicated"\n      operator: "Equal"\n      value: "Cassandra"\n      effect: "NoSchedule"\n...\n')),(0,o.kt)("admonition",{type:"important"},(0,o.kt)("p",{parentName:"admonition"},"toleration must be used with node affinity on the same labels")),(0,o.kt)("h3",{id:"configuring-hard-antiaffinity-in-cassandra-cluster"},"Configuring hard antiAffinity in Cassandra cluster"),(0,o.kt)("p",null,"In development environment, we may have other concern than in production and we may allow our cluster to deploy several\nnodes on the same kubernetes nodes."),(0,o.kt)("p",null,"The boolean ",(0,o.kt)("inlineCode",{parentName:"p"},"hardAntiAffinity")," parameter in ",(0,o.kt)("inlineCode",{parentName:"p"},"CassandraCluster.spec")," will define if we want the constraint to be\n",(0,o.kt)("strong",{parentName:"p"},"Required")," or ",(0,o.kt)("strong",{parentName:"p"},"Preferred")),(0,o.kt)("p",null,"If ",(0,o.kt)("inlineCode",{parentName:"p"},"hardAntiAffinity=false")," then the podAntiAffinity will be ",(0,o.kt)("strong",{parentName:"p"},"preferred")," instead of ",(0,o.kt)("strong",{parentName:"p"},"required")," and then kubernetes\nwill try to not put the cassandra node on the kubernetes node ",(0,o.kt)("strong",{parentName:"p"},"BUT")," it will allow to do it if it has no other choices."),(0,o.kt)("h2",{id:"cassandra-notion-of-dc-and-racks"},"Cassandra notion of dc and racks"),(0,o.kt)("p",null,"As we previously see, the Cassandra rack awareness is defined using several Cassandra datacenters ",(0,o.kt)("inlineCode",{parentName:"p"},"dc"),"s and ",(0,o.kt)("inlineCode",{parentName:"p"},"rack"),"s.\nThe ",(0,o.kt)("inlineCode",{parentName:"p"},"CassandraCluster.spec.topology")," section allows us to define the virtual notion of DC & Rack.\nFor each we will define Kubernetes ",(0,o.kt)("inlineCode",{parentName:"p"},"labels")," that will be used for pod placement."),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"The name and numbers of labels used to define a DC & rack is not defined in advance and will be defined in each\nCassandraCluster manifests, depending on labels presents on Kubernetes Nodes and the required topology")),(0,o.kt)("h2",{id:"configure-the-cassandracluster-crd-for-dc--rack"},"Configure the CassandraCluster CRD for dc & rack"),(0,o.kt)("p",null,"If the section topology is missing:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"then CassKop will deploy without label constraints to any available kubernetes nodes in the cluster"),(0,o.kt)("li",{parentName:"ul"},"there will be only one DC defined named by default ",(0,o.kt)("strong",{parentName:"li"},"dc1")),(0,o.kt)("li",{parentName:"ul"},"there will be only one Rack defined named by default ",(0,o.kt)("strong",{parentName:"li"},"rack1"))),(0,o.kt)("p",null,"If the ",(0,o.kt)("strong",{parentName:"p"},"topology")," section is defined, this will enable to create specific Cassandra dcs and racks: this creates a\nspecific statefulset for each rack and deploys on Kubernetes nodes matching the desired Node Labels (the concatenation\nof DC labels + Rack labels for each statefulset)"),(0,o.kt)("p",null,"Example of topology section:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"...\n  nodesPerRacks: 3\n...\n  topology:\n    dc:\n      - name: dc1\n        labels:\n          location.k8s.myorg.com/site : Valbonne\n          location.k8s.myorg.com/building : HT2\n        rack:\n          - name: rack1\n            labels:\n              location.k8s.myorg.com/room : Salle_1\n              location.k8s.myorg.com/street : Rue_9\n          - name: rack2\n            labels:\n              location.k8s.myorg.com/room : Salle_1\n              location.k8s.myorg.com/street : Rue_10\n      - name: dc2\n        nodesPerRacks: 4\n        labels:\n          location.k8s.myorg.com/site : Valbonne\n          location.k8s.myorg.com/building : HT2\n        rack:\n          - name: rack1\n            labels:\n              location.k8s.myorg.com/room : Salle_1\n              location.k8s.myorg.com/street : Rue_11\n")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"This will create 2 Cassandra DC (",(0,o.kt)("inlineCode",{parentName:"li"},"dc1")," & ",(0,o.kt)("inlineCode",{parentName:"li"},"dc2"),")",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"For DC ",(0,o.kt)("inlineCode",{parentName:"li"},"dc1")," it will create 2 Racks : ",(0,o.kt)("inlineCode",{parentName:"li"},"rack1")," and ",(0,o.kt)("inlineCode",{parentName:"li"},"rack2"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"In each of these Racks there will be 3 Cassandra nodes"),(0,o.kt)("li",{parentName:"ul"},"The ",(0,o.kt)("inlineCode",{parentName:"li"},"dc1")," will have 6 nodes"))),(0,o.kt)("li",{parentName:"ul"},"For DC ",(0,o.kt)("inlineCode",{parentName:"li"},"dc2")," it will create 1 Rack : ",(0,o.kt)("inlineCode",{parentName:"li"},"rack1"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"the ",(0,o.kt)("inlineCode",{parentName:"li"},"dc2")," overwrite the global parameter ",(0,o.kt)("inlineCode",{parentName:"li"},"nodesPerRacks=3")," with a value of ",(0,o.kt)("inlineCode",{parentName:"li"},"4"),"."),(0,o.kt)("li",{parentName:"ul"},"The ",(0,o.kt)("inlineCode",{parentName:"li"},"dc2")," will have 4 nodes")))))),(0,o.kt)("admonition",{type:"important"},(0,o.kt)("p",{parentName:"admonition"},"We want to have the same numbers of Cassandra nodes in each Rack for a dedicated\nDatacenter. We can still have different values for different datacenters.")),(0,o.kt)("p",null,"The NodeSelectors labels for each Rack will be the aggregation of labels of the DC and the labels for the Racks :"),(0,o.kt)("p",null,"For instance with this example, NodeSelectors labels for ",(0,o.kt)("inlineCode",{parentName:"p"},"dc1")," / ",(0,o.kt)("inlineCode",{parentName:"p"},"rack2")," will be :"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"location.k8s.myorg.com/site : Valbonne\nlocation.k8s.myorg.com/building : HT2\nlocation.k8s.myorg.com/room : Salle_1\nlocation.k8s.myorg.com/street : Rue_10\n")),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"The ",(0,o.kt)("inlineCode",{parentName:"p"},"dc")," / ",(0,o.kt)("inlineCode",{parentName:"p"},"rack")," topology definition is generic and does not rely on particular labels. It uses the ones\ncorresponding to your needs.")),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"The names for the dc and rack must be lowercase and respect Kubernetes DNS naming which follow ",(0,o.kt)("a",{parentName:"p",href:"http://tools.ietf.org/html/rfc1123#section-2"},"RFC 1123\ndefinition")," which can be expressed with this regular expression :\n",(0,o.kt)("inlineCode",{parentName:"p"},"[a-z0-9]([-a-z0-9]*[a-z0-9])?"))),(0,o.kt)("h2",{id:"how-casskop-configures-dc-and-rack-in-cassandra"},"How CassKop configures dc and rack in Cassandra"),(0,o.kt)("p",null,"CassKop will add 2 specific labels on each created Pod to tell them in witch Cassandra DC and Rack they belong :"),(0,o.kt)("p",null,"Example :"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-text"},"cassandraclusters.db.orange.com.dc=dc1\ncassandraclusters.db.orange.com.rack=rack1\n")),(0,o.kt)("p",null,"Using the Kubernetes DownwardAPI, CassKop will inject into the Cassandra Image 2 environment variables, from these\n2 labels. Excerpt from the Statefulset template :"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-go"},'...\nv1.EnvVar{\n  Name: "CASSANDRA_DC",\n  ValueFrom: &v1.EnvVarSource{\n    FieldRef: &v1.ObjectFieldSelector{\n    FieldPath: "metadata.labels[\'cassandraclusters.db.orange.com.dc\']",\n    },\n  },\n},\nv1.EnvVar{\n  Name: "CASSANDRA_RACK",\n  ValueFrom: &v1.EnvVarSource{\n    FieldRef: &v1.ObjectFieldSelector{\n      FieldPath: "metadata.labels[\'cassandraclusters.db.orange.com.rack\']",\n    },\n  },\n},\n...\n')),(0,o.kt)("p",null,"In order to allow configuring Cassandra with the DC and Rack information, we use a specific ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/cscetbon/cassandra-image/"},"Cassandra\nImage"),", which has a startup script that will retrieve\nthese environment variables, and configure the Cassandra ",(0,o.kt)("inlineCode",{parentName:"p"},"cassandra-rackdc.properties")," file with the values for dc and\nrack."),(0,o.kt)("p",null,"The Cassandra Image makes use of the ",(0,o.kt)("inlineCode",{parentName:"p"},"GossipingPropertyFileSnitch")," Cassandra Snitch, so that both Kubernetes and Cassandra are aware of the chosen topology."))}u.isMDXComponent=!0},9693:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/topology-gke-example-0018aa0c83a7d37dc224e8528e9fc6e1.png"}}]);