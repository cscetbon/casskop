"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[1286],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>b});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=r.createContext({}),c=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},p=function(e){var t=c(e.components);return r.createElement(l.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),u=c(n),m=a,b=u["".concat(l,".").concat(m)]||u[m]||d[m]||o;return n?r.createElement(b,s(s({ref:t},p),{},{components:n})):r.createElement(b,s({ref:t},p))}));function b(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,s=new Array(o);s[0]=m;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[u]="string"==typeof e?e:a,s[1]=i;for(var c=2;c<o;c++)s[c]=n[c];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},2773:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>c});var r=n(7462),a=(n(7294),n(3905));const o={title:"Multi-CassKop",sidebar_label:"Multi-CassKop"},s=void 0,i={unversionedId:"operations/multi_casskop",id:"operations/multi_casskop",title:"Multi-CassKop",description:"Here is describes how perform some operations based on the MultiCasskop Operator.",source:"@site/docs/5_operations/4_multi_casskop.md",sourceDirName:"5_operations",slug:"/operations/multi_casskop",permalink:"/casskop/docs/operations/multi_casskop",draft:!1,editUrl:"https://github.com/cscetbon/casskop/edit/master/website/docs/5_operations/4_multi_casskop.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Multi-CassKop",sidebar_label:"Multi-CassKop"},sidebar:"docs",previous:{title:"Pods Operations",permalink:"/casskop/docs/operations/pods_operations"},next:{title:"Backup and restore",permalink:"/casskop/docs/operations/backup_restore"}},l={},c=[{value:"Remove a Kubernetes site used in a Cassandra Ring",id:"remove-a-kubernetes-site-used-in-a-cassandra-ring",level:2}],p={toc:c},u="wrapper";function d(e){let{components:t,...n}=e;return(0,a.kt)(u,(0,r.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Here is describes how perform some operations based on the MultiCasskop Operator."),(0,a.kt)("p",null,"The MultiCasskop operator manage nothing else than CassandraCluster ressources. Today, this is not through it that you will manage cassandra operations (this is the duty of Cassskop operator).\nSo the only things we will be able to work with are the CassandraCluster's informations and Kubernetes Cluster's client used."),(0,a.kt)("h2",{id:"remove-a-kubernetes-site-used-in-a-cassandra-ring"},"Remove a Kubernetes site used in a Cassandra Ring"),(0,a.kt)("p",null,"Performing a scale down at the MultiCasskop operator level, is by designed scaledown the number of CassandraCluster resource deployed, and so the number of Kubernetes Cluster clients used in the cassandra Ring."),(0,a.kt)("p",null,"To achieve this scaledown the following steps are required :"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"First of all you need to remove all cassandra DC associated to the Kubernetes Cluster client that you want to remove of the ",(0,a.kt)("inlineCode",{parentName:"p"},"MultiCasskop")," resource : "),(0,a.kt)("p",{parentName:"li"},"i - Ensure that there is no more data replicated on it. For example you can check and perform it in following this instructions : "),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-sh"},"cqlsh> DESCRIBE keyspace <keyspace name>\n\nCREATE KEYSPACE system_distributed WITH replication = {'class': 'NetworkTopologyStrategy', 'dc1': '1', 'dc2': '1', dc3': '1'}  AND durable_writes = true;\ncqls> ALTER KEYSPACE system_distributed WITH replication = {'class': 'NetworkTopologyStrategy', 'dc1': '1', 'dc3': '1'}  AND durable_writes = true;\n")),(0,a.kt)("p",{parentName:"li"},"ii - Change decrease the number of node per rack for the DC to 0 : "),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"...\nsite_a:\n  spec:\n    topology:\n      dc:\n        - name: dc1\n          nodesPerRacks: 1\n          config:\n            cassandra-yaml:\n              num_tokens: 256\n          labels:\n            failure-domain.beta.kubernetes.io/region: europe-west1\n          rack:\n            - name: rack1\n              rollingPartition: 0\n              labels:\n                failure-domain.beta.kubernetes.io/zone: europe-west1-b\nsite_b:\n  spec:\n    topology:\n      dc:\n        - name: dc2\n          nodesPerRacks: 0       <---- Downsize to 0\n          config:\n            cassandra-yaml:\n              num_tokens: 256\n          labels:\n            failure-domain.beta.kubernetes.io/region: europe-west1\n          rack:\n            - name: rack1\n              rollingPartition: 0\n              labels:\n                failure-domain.beta.kubernetes.io/zone: europe-west1-c\nsite_c:\n  spec:\n    topology:\n      dc:\n        - name: dc3\n          nodesPerRacks: 1\n          config:\n            cassandra-yaml:\n              num_tokens: 256\n          labels:\n            failure-domain.beta.kubernetes.io/region: europe-west1\n          rack:\n            - name: rack1\n              rollingPartition: 0\n              labels:\n                failure-domain.beta.kubernetes.io/zone: europe-west1-c\n...\n")),(0,a.kt)("p",{parentName:"li"},"iii -  This will perform the downscale of the nodes into the DC."))),(0,a.kt)("p",null,"2 - Remove all DC from site list :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"...\nsite_b:\n  spec:\n    topology:\n      dc:\n...\n")),(0,a.kt)("p",null,"3 - Remove the site of ",(0,a.kt)("inlineCode",{parentName:"p"},"MultiCasskop")," resource.\n4 - Remove manually the ",(0,a.kt)("inlineCode",{parentName:"p"},"CassandraCluster")," resource on the remote site."))}d.isMDXComponent=!0}}]);